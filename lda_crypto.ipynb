{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Vis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [\"coinbase.csv\", \"binance.csv\", \"ftx.csv\", \"kraken.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5543"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(file):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = pd.read_csv(file)\n",
    "        # print(data)\n",
    "        # data = json.load(f)\n",
    "    return (data);\n",
    "\n",
    "def write_data(file, data):\n",
    "    with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4);\n",
    "\n",
    "# Combine all the csv files into one\n",
    "\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = load_data(filename)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "data = frame.loc[:, [\"content\", \"score\"]]\n",
    "data = data.loc[(data.score <= 2)] # Grab only poor reviews\n",
    "content = json.loads(data.loc[:, \"content\"].to_json())\n",
    "\n",
    "# Prefilter step\n",
    "\n",
    "# Remove reviews with <= 50 chars\n",
    "data = [content[key] for key in content if len(content[key]) > 50];\n",
    "len(data)\n",
    "\n",
    "## Break each sentence into its own document\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Stop words are basically words that are not really useful in the topic model\n",
    "# i.e. words that you want to eliminate from consideration\n",
    "stopwords = stopwords.words(\"english\")\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO NOT RECOMMEND - They have no problem taking your money to buy crypto, but then mistaken\n"
     ]
    }
   ],
   "source": [
    "# data = load_data(\"ushmm_dn.json\")[\"texts\"]\n",
    "print(data[0][0:90]) # Prints out first text, char 0-89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem money crypto suspicious customer service flat problem problem money access smart g\n"
     ]
    }
   ],
   "source": [
    "# Reducing words to their root form (lemma) using spacy or nltk to grab roots\n",
    "# Specify allowed_postags for spacy\n",
    "\n",
    "# Takes a list of texts i.e. [text1, text2...] and returns lemmatised [text1..]\n",
    "# Allowed_post_tages -> Basically default arguments in python \n",
    "# This is a list initalised that is used to filter tokens \n",
    "# pos_ tag marks category of word token belongs to i.e. only append nouns,adj,verbs,and adverbs \n",
    "# e.g. conjunctions (but, and, because), and pronouns (he/she) is ignored\n",
    "def lemmatization(texts, allowed_postags=[\"NOUN\", \"ADJ\"]):\n",
    "\n",
    "    # Spacy load creates an an nlp parser i.e. function pointer \n",
    "    spacy.load\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    texts_out = []\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp(text) # Create document from the raw text/string\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags and token.pos_ not in stopwords:\n",
    "               new_text.append(token.lemma_) # Appends only lemma to new_text\n",
    "        final = \" \".join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return (texts_out);\n",
    "\n",
    "lemmatized_texts = lemmatization(data)\n",
    "print(lemmatized_texts[0][0:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['problem', 'money', 'crypto', 'suspicious', 'customer', 'service', 'flat', 'problem', 'problem', 'money', 'access', 'smart', 'guy', 'form', 'theft', 'good', 'luck', 'clown']\n"
     ]
    }
   ],
   "source": [
    "# Simple preprocess converts documents to list of lower case tokens ignoring ones\n",
    "# which are too short or too long.\n",
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True);\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)\n",
    "\n",
    "print(data_words[0][0:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIGRAMS AND TRIGRAMS\n",
    "\n",
    "# min_count - ignore all words/bigrams with total collected count lower than this value.\n",
    "# threshold - score for forming phrases play around with this -> related to scoring function\n",
    "bigrams_phrases = gensim.models.Phrases(data_words, min_count=5, threshold=1) \n",
    "\n",
    "# First arg checks ensures no overlap between bigraph phrases and trigram phrases.\n",
    "trigram_phrases = gensim.models.Phrases(bigrams_phrases[data_words], threshold=1)\n",
    "\n",
    "# Create function pointer i.e. phraser that converts document to list of bigram\n",
    "bigram = gensim.models.phrases.Phraser(bigrams_phrases)\n",
    "trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return([bigram[doc] for doc in texts])\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return ([trigram[bigram[doc]] for doc in texts])\n",
    "\n",
    "data_bigrams = make_bigrams(data_words)\n",
    "data_bigrams_trigrams = make_trigrams(data_bigrams)\n",
    "\n",
    "# print(data_bigrams_trigrams[0])\n",
    "\n",
    "# new_words = []\n",
    "# for word in data_bigrams_trigrams[0]:\n",
    "#     if '_' in word:\n",
    "#         new_words.append(word)\n",
    "# print(data_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 3), (10, 1), (11, 1), (12, 1)]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Removal - to remove words that are not important to the topic\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "id2word = corpora.Dictionary(data_bigrams_trigrams)\n",
    "\n",
    "texts = data_bigrams_trigrams\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "print(corpus[0][0:20])\n",
    "\n",
    "tfidf = TfidfModel(corpus, id2word=id2word)\n",
    "\n",
    "# Goes through words and looks at words that occur too frequentely and removes them\n",
    "# Corpus becomes new corpus where those irrelevant words are removed\n",
    "# low_value = 0.03\n",
    "low_value = 0.2 # TODO\n",
    "words = []\n",
    "words_missing_in_tfidf = []\n",
    "for i in range(0, len(corpus)):\n",
    "    bow = corpus[i]\n",
    "    low_value_words = []\n",
    "    tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "    bow_ids = [id for id, value in bow]\n",
    "    low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    drops = low_value_words + words_missing_in_tfidf\n",
    "    for item in drops:\n",
    "        words.append(id2word[item])\n",
    "    words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids]\n",
    "\n",
    "    new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_missing_in_tfidf]\n",
    "    corpus[i] = new_bow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2word = corpora.Dictionary(data_words)\n",
    "# corpus = []\n",
    "# for text in data_words:\n",
    "#     new = id2word.doc2bow(text) # Create a bag of words all (word: f pairs) for 1 doc\n",
    "#     corpus.append(new)\n",
    "\n",
    "# print(corpus[0][0:20])\n",
    "# #(0,2) - 0 = index of word in the dictionary, 2 = frequency of word in that text\n",
    "\n",
    "# word = id2word[[0][:1][0]] # i.e. text 1 -> first tuple -> first value in tuple\n",
    "# print(word) # i.e. able is the first element in teh dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(corpus=corpus\n",
    "                                    ,id2word=id2word\n",
    "                                    ,num_topics=6\n",
    "                                    ,random_state=100\n",
    "                                    ,update_every=1\n",
    "                                    ,chunksize=100\n",
    "                                    ,passes=10\n",
    "                                    ,alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea\n",
    "I think I can separate the review data set into one star vs 5 star reviews and look at if there are any differences in the topics that are mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/root/miniconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/root/miniconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/root/miniconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/root/miniconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el31701399870134497602903480073\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el31701399870134497602903480073_data = {\"mdsDat\": {\"x\": [0.11546742847157095, -0.11082656180688877, -0.3266965076732382, -0.21551113183810178, 0.22213765772454913, 0.3154291151221087], \"y\": [0.30717203071523214, -0.31929320489326, -0.06028457076692637, 0.2641978152126022, -0.2500166500864369, 0.0582245798187891], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [20.431264545862383, 17.650385118272823, 16.270990603948757, 15.638502938702423, 15.3907289843314, 14.618127808882212]}, \"tinfo\": {\"Term\": [\"account\", \"app\", \"shib\", \"fee\", \"crypto\", \"promise\", \"kraken\", \"money\", \"company\", \"day\", \"time\", \"star\", \"coin\", \"exchange\", \"bank\", \"transaction\", \"option\", \"verification\", \"update\", \"error\", \"platform\", \"good\", \"website\", \"portfolio\", \"way\", \"terrible\", \"shiba\", \"people\", \"bad\", \"hour\", \"money\", \"website\", \"portfolio\", \"way\", \"hour\", \"customer\", \"new\", \"more\", \"password\", \"liar\", \"currency\", \"waste_time\", \"available\", \"withdrawal\", \"transfer\", \"limited\", \"purchase\", \"application\", \"fund\", \"much\", \"one\", \"wrong\", \"payment\", \"order\", \"coinbase\", \"trade\", \"ftx\", \"first\", \"error_message\", \"debit_card\", \"server\", \"app\", \"crypto\", \"day\", \"time\", \"exchange\", \"kraken\", \"terrible\", \"bad\", \"second\", \"many\", \"week\", \"joke\", \"big\", \"page\", \"interface\", \"scam\", \"frustrating\", \"clear\", \"minute\", \"list\", \"ridiculous\", \"message\", \"multiple\", \"simple\", \"ceo\", \"great_app\", \"responsive\", \"user_friendly\", \"disappointing\", \"track\", \"bank\", \"platform\", \"problem\", \"code\", \"deposit\", \"able\", \"email\", \"great\", \"phone\", \"other\", \"unable\", \"well\", \"web\", \"disappointed\", \"version\", \"info\", \"number\", \"buggy\", \"top\", \"crash\", \"asset\", \"horrible\", \"browser\", \"help\", \"credential\", \"app_good\", \"pin\", \"use\", \"profit\", \"usable\", \"shib\", \"option\", \"error\", \"good\", \"people\", \"price\", \"slow\", \"word\", \"review\", \"screen\", \"support\", \"market\", \"service\", \"garbage\", \"easy\", \"thing\", \"poor\", \"community\", \"euro\", \"few\", \"last\", \"trading\", \"month\", \"charge\", \"high\", \"glitch\", \"amount\", \"rating\", \"sorry\", \"less\", \"section\", \"inu\", \"account\", \"promise\", \"company\", \"star\", \"update\", \"useless\", \"bad_app\", \"login\", \"address\", \"lie\", \"business\", \"difficult\", \"impossible\", \"today\", \"bug\", \"process\", \"false\", \"wallet\", \"name\", \"old\", \"response\", \"unusable\", \"invalid\", \"basic\", \"customer_service\", \"careful\", \"open\", \"fine\", \"few_day\", \"username\", \"check\", \"fee\", \"coin\", \"transaction\", \"verification\", \"shiba\", \"guy\", \"issue\", \"credit_card\", \"whole\", \"site\", \"datum\", \"bitcoin\", \"user\", \"high_fee\", \"card\", \"same\", \"functionality\", \"bank_account\", \"information\", \"trust\", \"feature\", \"reason\", \"investor\", \"lot\", \"shame\", \"annoying\", \"different\", \"developer\", \"listing\", \"app_unusable\"], \"Freq\": [374.0, 327.0, 265.0, 238.0, 246.0, 200.0, 212.0, 220.0, 184.0, 193.0, 190.0, 172.0, 165.0, 178.0, 164.0, 150.0, 152.0, 143.0, 139.0, 134.0, 132.0, 129.0, 147.0, 145.0, 143.0, 131.0, 114.0, 116.0, 124.0, 136.0, 219.45860860186656, 147.07022119433148, 144.79734080950377, 143.15988725269298, 135.39379335464506, 110.16444018316045, 101.8337629379213, 97.83532802012797, 90.84450841224621, 88.40021007381407, 84.80736854624381, 82.53301916181368, 80.32574975922786, 77.46557503335579, 76.64754375476215, 78.31042530469068, 72.76363880597043, 71.18696673270865, 63.40719033836402, 63.753256744698525, 60.29707118014131, 58.86787756696338, 59.11267400070737, 58.420664688004926, 54.08377811181611, 52.15146513481124, 51.005983444844524, 50.180171668356735, 49.36160413990823, 45.45531319717544, 46.387614444841056, 326.3008538780347, 245.58937306109132, 192.27534059530566, 189.63193167268005, 178.06715240314912, 211.693147627997, 130.3139190044741, 124.00078340463841, 87.97996813836912, 82.07920257849263, 79.54590387433399, 62.89750725298163, 62.83241481315965, 56.537158296173644, 54.64263811831149, 53.13802682104964, 50.71188469290229, 49.675335880229895, 46.80977766861039, 43.9331236442676, 43.75124721400415, 43.07317569705426, 39.798237587315235, 39.16321007463168, 39.90628980205595, 38.19910411618146, 39.35782759754145, 38.67521050346631, 37.232047322920465, 37.133235067611, 163.50133758730118, 132.10287880420813, 111.4081581795982, 110.95986729509188, 108.57705438806683, 80.07067797228265, 79.65984905321791, 74.33651256393269, 72.22799971891533, 71.21226125755778, 70.63199679160428, 70.375136188153, 65.55237790034596, 63.838978273539304, 60.98352446329337, 58.3984314369425, 57.63238937284983, 49.10043062586562, 46.90491719314938, 46.80006303092957, 45.70768723388561, 43.74311592169043, 43.02928870427585, 42.573370321347774, 42.34273361135055, 41.79896311477153, 41.81621104469434, 40.5213713643653, 40.415236030880216, 40.18398849983531, 264.1684174798616, 151.82255837351414, 134.17733777964241, 128.80233803085937, 116.19764241911024, 114.34575233468263, 113.97528675374801, 109.89862304214768, 83.93278788944443, 83.49179344713984, 79.4325330902991, 77.03081540594364, 76.83606002513618, 63.744722235256475, 63.28492639854466, 60.159103780392265, 57.43582205138923, 60.466911313916256, 53.35896928104651, 49.33268972429193, 47.938535731330155, 45.60674988073711, 40.25511132471383, 41.022314188929585, 38.90066215526806, 39.35136575904015, 38.18404494271561, 38.140481828285914, 35.54983724514153, 34.698622646085695, 34.9629864707015, 70.34923068853378, 373.8120718163924, 199.23725551430397, 183.84212133063392, 171.5712058276751, 139.05414249109725, 107.64257930073299, 86.37414079872704, 86.04327124155037, 73.85654939348328, 71.94028320181518, 70.24860034070355, 66.97386622228532, 65.17907979670409, 64.19458446545642, 60.907937397788324, 58.47838614368091, 58.6611199151586, 53.97915948584302, 43.03824422079802, 42.831332009782365, 42.653915732297826, 41.53502392303517, 40.348745363237626, 38.61702950867472, 37.39517857884005, 36.98488201539259, 34.22685309712476, 33.641157574355915, 32.8701552201707, 32.01813452863941, 33.26013905449235, 237.93541777176418, 164.8189845791667, 149.61926250368057, 142.22864627761268, 113.5744172378377, 93.9679091136623, 91.15376102458141, 82.45524497238425, 72.93188776071041, 71.42606270309881, 69.30317170551606, 69.77906378503754, 62.03278300087211, 62.2656156969919, 57.922510425451726, 55.10578589946581, 55.97026419205002, 54.40023748917858, 52.900997692681635, 53.12954252810389, 49.67328032365386, 48.86107486647136, 46.77036142655271, 43.845421899947375, 42.085789903541446, 39.553040811301, 38.16017437460329, 36.312934222210046, 50.25327626620623, 34.412628305728624], \"Total\": [374.0, 327.0, 265.0, 238.0, 246.0, 200.0, 212.0, 220.0, 184.0, 193.0, 190.0, 172.0, 165.0, 178.0, 164.0, 150.0, 152.0, 143.0, 139.0, 134.0, 132.0, 129.0, 147.0, 145.0, 143.0, 131.0, 114.0, 116.0, 124.0, 136.0, 220.23896916544717, 147.85863297575918, 145.57530761839024, 143.9432310274963, 136.18600788339634, 110.94963048725621, 102.61571730915409, 98.61637341711877, 91.6230155086636, 89.19372185948042, 85.59492115192424, 83.32223314951666, 81.10702209956094, 78.25702605600318, 77.43163859532578, 79.11596860099638, 73.54639850639454, 71.96732664913809, 64.18737219670953, 64.538466229771, 61.077810112858614, 59.64694681817575, 59.90589659673419, 59.207129825842806, 54.86853776404543, 52.93226268506282, 51.78482590893075, 50.96753532657023, 50.14527612113629, 46.24012114602776, 47.558596159809035, 327.08164024151205, 246.37234194597875, 193.0590619299822, 190.41388288242314, 178.85048837924032, 212.79571465454885, 131.09779741269915, 124.78311506376038, 88.77220867876032, 82.8631372953956, 80.32879394997387, 63.681518107536434, 63.61789617953265, 57.32182143062784, 55.43335099498161, 53.91987915056475, 51.49445621047498, 50.46242884787926, 47.59295734614802, 44.71735892404421, 44.53492257226322, 43.85412220920934, 40.589088651196384, 39.9451793101654, 40.70861601147801, 38.978151136594185, 40.16215420694847, 39.4673306772157, 38.01399871779495, 37.92091385804833, 164.29718025442583, 132.89825108397878, 112.19934639291515, 111.75355954184327, 109.37150063220216, 80.86241093735664, 80.45000366508685, 75.12652536800658, 73.01953489052448, 72.00378732077215, 71.42308578789657, 71.16623049383053, 66.35463817012003, 64.63049765876134, 61.781352174863095, 59.18907458405768, 58.42775978460318, 49.89229270919298, 47.701573089344095, 47.601162138980676, 46.49704846969103, 44.53382970618942, 43.82383200367676, 43.36476791960056, 43.13825045318423, 42.59278306263625, 42.62819495717849, 41.313820882308654, 41.213573671285474, 40.98844244976431, 265.02515220525777, 152.62813844314402, 134.98189269470126, 129.60517193943798, 116.99868670501789, 115.14544793341558, 114.77980097533688, 110.7118641374243, 84.73409358066353, 84.29829625435696, 80.23109882077902, 77.83330931153351, 77.63902751152439, 64.54688265795669, 64.09073281251169, 60.960670044533884, 58.240576750033405, 61.338382759303315, 54.190769034768934, 50.14723343936761, 48.742319689150825, 46.4103338857631, 41.05254949260904, 41.83562275640375, 39.705587685915766, 40.1729139667042, 38.98580366831524, 38.94268635435743, 36.36972382068785, 35.50609973054325, 35.789913873624705, 80.52744793258675, 374.6009224844883, 200.08668272440264, 184.63391165331137, 172.3596947741246, 139.8381777207351, 108.43327985163185, 87.1637514203729, 86.83254358949812, 74.65300483246368, 72.75271184001788, 71.04491429168675, 67.7701278446586, 65.97932844552598, 64.98459723959415, 61.69724639276584, 59.26635889310422, 59.457573041713495, 54.7681964466217, 43.82683267469466, 43.621733184447216, 43.4439537211288, 42.32239539517461, 41.139324076032956, 39.41747250857409, 38.18208292981368, 37.80034182385209, 35.0122755080561, 34.43005116711796, 33.66434162328295, 32.814211717557136, 34.096668860892514, 238.73267502456662, 165.60544891002087, 150.40647082442598, 143.02027131644314, 114.39906089606684, 94.75471157660591, 91.94022223227132, 83.27093953685518, 73.7209189087382, 72.22061793144444, 70.08617289489516, 70.57233035901253, 62.817842723978806, 63.06384946894464, 58.709651578990304, 55.89290835739569, 56.77582895017104, 55.18960750444025, 53.686916388153456, 53.92645318530012, 50.46228890636284, 49.64626191828617, 47.59134281082098, 44.636280021789645, 42.874778610556575, 40.33925654333377, 38.948577008286385, 37.10008063752153, 51.343563767216885, 35.2084838619267], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.4595, -3.8598, -3.8754, -3.8867, -3.9425, -4.1487, -4.2274, -4.2674, -4.3416, -4.3688, -4.4103, -4.4375, -4.4646, -4.5009, -4.5115, -4.49, -4.5635, -4.5854, -4.7011, -4.6957, -4.7514, -4.7754, -4.7713, -4.783, -4.8602, -4.8966, -4.9188, -4.9351, -4.9515, -5.034, -5.0137, -2.9166, -3.2007, -3.4455, -3.4593, -3.5222, -3.3493, -3.8345, -3.8841, -4.2273, -4.2967, -4.3281, -4.5629, -4.5639, -4.6695, -4.7036, -4.7315, -4.7782, -4.7989, -4.8583, -4.9217, -4.9259, -4.9415, -5.0206, -5.0367, -5.0179, -5.0616, -5.0317, -5.0492, -5.0872, -5.0899, -3.5262, -3.7394, -3.9098, -3.9139, -3.9356, -4.2401, -4.2453, -4.3144, -4.3432, -4.3574, -4.3655, -4.3692, -4.4402, -4.4667, -4.5124, -4.5557, -4.5689, -4.7292, -4.7749, -4.7771, -4.8008, -4.8447, -4.8611, -4.8718, -4.8772, -4.8902, -4.8897, -4.9212, -4.9238, -4.9296, -3.0068, -3.5607, -3.6842, -3.7251, -3.8281, -3.8441, -3.8474, -3.8838, -4.1534, -4.1586, -4.2085, -4.2392, -4.2417, -4.4285, -4.4357, -4.4864, -4.5327, -4.4813, -4.6063, -4.6848, -4.7135, -4.7633, -4.8881, -4.8693, -4.9224, -4.9108, -4.941, -4.9421, -5.0124, -5.0367, -5.0291, -4.3299, -2.6437, -3.2729, -3.3533, -3.4224, -3.6325, -3.8886, -4.1087, -4.1126, -4.2653, -4.2916, -4.3154, -4.3631, -4.3903, -4.4055, -4.458, -4.4987, -4.4956, -4.5788, -4.8053, -4.8101, -4.8143, -4.8409, -4.8698, -4.9137, -4.9459, -4.9569, -5.0344, -5.0517, -5.0748, -5.1011, -5.063, -3.0439, -3.4111, -3.5078, -3.5585, -3.7834, -3.9729, -4.0034, -4.1036, -4.2264, -4.2472, -4.2774, -4.2706, -4.3882, -4.3845, -4.4568, -4.5066, -4.4911, -4.5195, -4.5475, -4.5432, -4.6104, -4.6269, -4.6707, -4.7352, -4.7762, -4.8383, -4.8741, -4.9237, -4.5988, -4.9775], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5846, 1.5828, 1.5827, 1.5826, 1.5823, 1.581, 1.5805, 1.5802, 1.5796, 1.5792, 1.5789, 1.5786, 1.5784, 1.5779, 1.5779, 1.5779, 1.5774, 1.5772, 1.5759, 1.5759, 1.5752, 1.575, 1.5748, 1.5747, 1.5737, 1.5732, 1.5729, 1.5725, 1.5724, 1.571, 1.5632, 1.732, 1.7312, 1.7303, 1.7303, 1.73, 1.7292, 1.7284, 1.7281, 1.7254, 1.7249, 1.7246, 1.722, 1.722, 1.7206, 1.72, 1.7198, 1.7191, 1.7187, 1.7178, 1.7167, 1.7167, 1.7164, 1.7147, 1.7146, 1.7145, 1.7142, 1.7142, 1.7141, 1.7136, 1.7134, 1.8109, 1.8098, 1.8087, 1.8087, 1.8085, 1.8059, 1.8059, 1.8052, 1.8049, 1.8047, 1.8046, 1.8046, 1.8036, 1.8035, 1.8028, 1.8023, 1.8021, 1.7998, 1.7989, 1.7988, 1.7987, 1.7979, 1.7975, 1.7974, 1.7972, 1.797, 1.7966, 1.7964, 1.7962, 1.796, 1.8522, 1.8501, 1.8495, 1.8492, 1.8486, 1.8485, 1.8484, 1.8481, 1.8459, 1.8458, 1.8454, 1.8451, 1.845, 1.8429, 1.8428, 1.8422, 1.8415, 1.8411, 1.84, 1.8391, 1.8388, 1.838, 1.8358, 1.8358, 1.835, 1.8348, 1.8347, 1.8346, 1.8326, 1.8324, 1.8321, 1.7203, 1.8693, 1.8672, 1.8671, 1.8668, 1.8658, 1.8641, 1.8623, 1.8623, 1.8607, 1.8602, 1.8601, 1.8596, 1.8592, 1.8592, 1.8585, 1.858, 1.8579, 1.8569, 1.8532, 1.8531, 1.8531, 1.8526, 1.852, 1.8509, 1.8506, 1.8496, 1.8487, 1.8482, 1.8475, 1.8468, 1.8466, 1.9196, 1.9181, 1.9177, 1.9174, 1.9157, 1.9146, 1.9143, 1.9131, 1.9121, 1.9118, 1.9117, 1.9116, 1.9103, 1.9102, 1.9094, 1.9087, 1.9086, 1.9085, 1.9082, 1.908, 1.9071, 1.907, 1.9055, 1.905, 1.9043, 1.9032, 1.9025, 1.9015, 1.9014, 1.9]}, \"token.table\": {\"Topic\": [3, 5, 5, 4, 6, 2, 3, 6, 1, 3, 1, 2, 5, 3, 6, 5, 2, 6, 3, 5, 3, 5, 6, 5, 2, 4, 5, 2, 3, 6, 1, 4, 5, 3, 3, 6, 2, 1, 1, 5, 6, 2, 1, 3, 6, 6, 5, 3, 2, 4, 3, 4, 1, 4, 2, 5, 6, 6, 4, 5, 5, 1, 2, 1, 6, 1, 4, 4, 4, 3, 2, 6, 3, 4, 6, 3, 1, 5, 3, 6, 2, 1, 2, 3, 4, 5, 6, 5, 6, 6, 2, 2, 4, 4, 1, 5, 1, 2, 6, 5, 6, 2, 4, 2, 2, 1, 4, 1, 1, 2, 5, 1, 3, 5, 1, 5, 4, 1, 3, 2, 1, 1, 4, 3, 3, 3, 4, 1, 4, 3, 5, 3, 5, 1, 4, 6, 5, 2, 4, 2, 6, 2, 4, 2, 4, 1, 4, 6, 4, 6, 2, 6, 4, 4, 5, 4, 2, 4, 2, 5, 3, 2, 1, 4, 6, 1, 6, 3, 5, 5, 3, 3, 5, 6, 2, 5, 6, 3, 5, 1, 1, 3, 1, 2, 3, 6, 1, 4, 1], \"Freq\": [0.9893348352175061, 0.9983958328759504, 0.9912527990811736, 0.97471377846402, 0.9915899158188667, 0.9966930573030226, 0.9860825468538998, 0.9656763447507174, 0.9865588080844785, 0.9893101070702363, 0.9863510942591132, 0.9937241904615041, 0.9866486767560019, 0.9981912029532971, 0.9784450812710611, 0.9894089478090387, 0.9902873842638725, 0.9918901592720406, 0.9812012787104595, 0.9886989058097154, 0.9821156202543371, 0.9852922013897197, 0.9879125227300062, 0.9788271273423493, 0.98259297217871, 0.9800260471495947, 0.9678364808783315, 0.990836175379642, 0.9932569526650189, 0.9963440278444592, 0.98417056842702, 0.9781803383282008, 0.9965666564303655, 0.9873708516353977, 0.9736138939056067, 0.9847372979826573, 0.9984887023314476, 0.9930495741579305, 0.991440886435712, 0.9690408998381103, 0.9845023226403867, 0.9945143112196086, 0.9731808413280013, 0.9966033141169797, 0.970348295243085, 0.9756454001365807, 0.9886361754190006, 0.9902445798562427, 0.973325649708083, 0.9829814270387192, 0.9944064183395166, 0.9927257450973659, 0.977160837276683, 0.9780263492107866, 0.9952446963553327, 0.9923042092318084, 0.9908389231566436, 0.9969309813811987, 0.9771226972918712, 0.9802657176332991, 0.9875094241065585, 0.9810166349938088, 0.9903978749002811, 0.9848444810780874, 0.9863352246102485, 0.9815014674059145, 0.9915273575510269, 0.9708033634882367, 0.9953306497697425, 0.9850049584685527, 0.9749051428025313, 0.9920351023812072, 0.9915883806809055, 0.9822295115867017, 0.9831305973564376, 0.9880129396076792, 0.9912912647794786, 0.9851570413249274, 0.9799105731519926, 0.9872051435551431, 0.9921824860448931, 0.024836252127029935, 0.024836252127029935, 0.024836252127029935, 0.8692688244460477, 0.024836252127029935, 0.024836252127029935, 0.9723057171788414, 0.9875745718465727, 0.9897735484052235, 0.989298023542944, 0.9962606641029373, 0.9847705301289538, 0.9857461187124451, 0.9866165259774554, 0.9896538311633925, 0.9858945214129334, 0.9839579317449696, 0.9738318950100858, 0.9904120787543208, 0.9857452273917308, 0.9895835793385588, 0.9892936672113204, 0.9805235593330385, 0.9875410695360789, 0.9943744325986359, 0.9743609226316495, 0.9937497862093175, 0.9916566621237334, 0.985486526779186, 0.9811340992667247, 0.9939997758111547, 0.9926788261918625, 0.9857471691503333, 0.9823534912128143, 0.9710879829040766, 0.9958845174320329, 0.9796117489668293, 0.9860592427409361, 0.9943857082242699, 0.993200229165076, 0.9848780062030893, 0.9914641203833696, 0.9860375050039276, 0.9852633929771237, 0.993241061664452, 0.9786990991631501, 0.996048041197355, 0.990052164857807, 0.9893105759394077, 0.9786327536100491, 0.9705540295785852, 0.9945689402732544, 0.9925706966283736, 0.9757929808493566, 0.9869826671069442, 0.9897810009655524, 0.9710634494116004, 0.9913365028214446, 0.98798869423439, 0.9840246574451598, 0.9829398884964838, 0.984598784174243, 0.9913012339080723, 0.9779291485189399, 0.9672278770682853, 0.991769248894449, 0.9795968949833553, 0.9961318682520224, 0.996511676818489, 0.976338088187656, 0.9830987609022799, 0.9932061131949127, 0.989834296721342, 0.9979131155076831, 0.9846555906765148, 0.9916261185590841, 0.9842411501738403, 0.997826403851663, 0.9848487598382121, 0.9852924538142576, 0.975714882254799, 0.9823876283050734, 0.9911585663922798, 0.9972975177052026, 0.9944255526144602, 0.9828200608314314, 0.9940763440387749, 0.9923823925332126, 0.99400608807697, 0.9758848497115803, 0.9924039734014765, 0.996004180153688, 0.9869807257219513, 0.9881590503032046, 0.975187223006747, 0.992866246812064, 0.9873529447421029, 0.9859736763950151, 0.9961326870711874, 0.9934472012281278, 0.9946554124941379, 0.9941928789785311, 0.9959068979651476, 0.9836125858326636, 0.9902209722910447, 0.9839372115277724, 0.9935701187675724, 0.9891537312019026], \"Term\": [\"able\", \"account\", \"address\", \"amount\", \"annoying\", \"app\", \"app_good\", \"app_unusable\", \"application\", \"asset\", \"available\", \"bad\", \"bad_app\", \"bank\", \"bank_account\", \"basic\", \"big\", \"bitcoin\", \"browser\", \"bug\", \"buggy\", \"business\", \"card\", \"careful\", \"ceo\", \"charge\", \"check\", \"clear\", \"code\", \"coin\", \"coinbase\", \"community\", \"company\", \"crash\", \"credential\", \"credit_card\", \"crypto\", \"currency\", \"customer\", \"customer_service\", \"datum\", \"day\", \"debit_card\", \"deposit\", \"developer\", \"different\", \"difficult\", \"disappointed\", \"disappointing\", \"easy\", \"email\", \"error\", \"error_message\", \"euro\", \"exchange\", \"false\", \"feature\", \"fee\", \"few\", \"few_day\", \"fine\", \"first\", \"frustrating\", \"ftx\", \"functionality\", \"fund\", \"garbage\", \"glitch\", \"good\", \"great\", \"great_app\", \"guy\", \"help\", \"high\", \"high_fee\", \"horrible\", \"hour\", \"impossible\", \"info\", \"information\", \"interface\", \"inu\", \"inu\", \"inu\", \"inu\", \"inu\", \"inu\", \"invalid\", \"investor\", \"issue\", \"joke\", \"kraken\", \"last\", \"less\", \"liar\", \"lie\", \"limited\", \"list\", \"listing\", \"login\", \"lot\", \"many\", \"market\", \"message\", \"minute\", \"money\", \"month\", \"more\", \"much\", \"multiple\", \"name\", \"new\", \"number\", \"old\", \"one\", \"open\", \"option\", \"order\", \"other\", \"page\", \"password\", \"payment\", \"people\", \"phone\", \"pin\", \"platform\", \"poor\", \"portfolio\", \"price\", \"problem\", \"process\", \"profit\", \"promise\", \"purchase\", \"rating\", \"reason\", \"response\", \"responsive\", \"review\", \"ridiculous\", \"same\", \"scam\", \"screen\", \"second\", \"section\", \"server\", \"service\", \"shame\", \"shib\", \"shiba\", \"simple\", \"site\", \"slow\", \"sorry\", \"star\", \"support\", \"terrible\", \"thing\", \"time\", \"today\", \"top\", \"track\", \"trade\", \"trading\", \"transaction\", \"transfer\", \"trust\", \"unable\", \"unusable\", \"update\", \"usable\", \"use\", \"useless\", \"user\", \"user_friendly\", \"username\", \"verification\", \"version\", \"wallet\", \"waste_time\", \"way\", \"web\", \"website\", \"week\", \"well\", \"whole\", \"withdrawal\", \"word\", \"wrong\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 6, 1, 4, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el31701399870134497602903480073\", ldavis_el31701399870134497602903480073_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el31701399870134497602903480073\", ldavis_el31701399870134497602903480073_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el31701399870134497602903480073\", ldavis_el31701399870134497602903480073_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4      0.115467  0.307172       1        1  20.431265\n",
       "5     -0.110827 -0.319293       2        1  17.650385\n",
       "0     -0.326697 -0.060285       3        1  16.270991\n",
       "3     -0.215511  0.264198       4        1  15.638503\n",
       "1      0.222138 -0.250017       5        1  15.390729\n",
       "2      0.315429  0.058225       6        1  14.618128, topic_info=              Term        Freq       Total Category  logprob  loglift\n",
       "74         account  374.000000  374.000000  Default  30.0000  30.0000\n",
       "23             app  327.000000  327.000000  Default  29.0000  29.0000\n",
       "759           shib  265.000000  265.000000  Default  28.0000  28.0000\n",
       "97             fee  238.000000  238.000000  Default  27.0000  27.0000\n",
       "2           crypto  246.000000  246.000000  Default  26.0000  26.0000\n",
       "...            ...         ...         ...      ...      ...      ...\n",
       "239       annoying   39.553041   40.339257   Topic6  -4.8383   1.9032\n",
       "676      different   38.160174   38.948577   Topic6  -4.8741   1.9025\n",
       "51       developer   36.312934   37.100081   Topic6  -4.9237   1.9015\n",
       "3963       listing   50.253276   51.343564   Topic6  -4.5988   1.9014\n",
       "1153  app_unusable   34.412628   35.208484   Topic6  -4.9775   1.9000\n",
       "\n",
       "[214 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "447       3  0.989335        able\n",
       "74        5  0.998396     account\n",
       "284       5  0.991253     address\n",
       "62        4  0.974714      amount\n",
       "239       6  0.991590    annoying\n",
       "...     ...       ...         ...\n",
       "436       3  0.983613        well\n",
       "1410      6  0.990221       whole\n",
       "667       1  0.983937  withdrawal\n",
       "1291      4  0.993570        word\n",
       "92        1  0.989154       wrong\n",
       "\n",
       "[189 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 6, 1, 4, 2, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualising the data\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=30)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further preprocessing\n",
    "\n",
    "\n",
    "def pre_process_unseen(unseen_document, useless_words=[\"app\", \"shib\", \"day\", \"time\", \"kraken\", \"hour\", \"money\"]):\n",
    "    words = \" \".join(lemmatization([unseen_document]))\n",
    "    cleaned_words = [\" \".join(gen_words([w])[0])]\n",
    "    cleaned_words = [word for word in cleaned_words if word not in useless_words]\n",
    "    return cleaned_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029*\"bank\" + 0.024*\"platform\" + 0.020*\"problem\" + 0.020*\"code\" + 0.020*\"deposit\"\n",
      "0.071*\"account\" + 0.038*\"promise\" + 0.035*\"company\" + 0.033*\"star\" + 0.026*\"update\"\n",
      "0.048*\"fee\" + 0.033*\"coin\" + 0.030*\"transaction\" + 0.028*\"verification\" + 0.023*\"shiba\"\n",
      "0.049*\"shib\" + 0.028*\"option\" + 0.025*\"error\" + 0.024*\"good\" + 0.022*\"people\"\n",
      "0.031*\"money\" + 0.021*\"website\" + 0.021*\"portfolio\" + 0.021*\"way\" + 0.019*\"hour\"\n",
      "0.054*\"app\" + 0.041*\"crypto\" + 0.035*\"kraken\" + 0.032*\"day\" + 0.031*\"time\"\n"
     ]
    }
   ],
   "source": [
    "labels = {1: \"transaction\", 2: \"trust\", 3: \"fee\", 4: \"idk\", 5: \"idk\", 6: \"app\"}\n",
    "for i in range(len(lda_model.get_topics())):\n",
    "    print(lda_model.print_topic(i, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.22350287437438965\t Topic: 0.029*\"bank\" + 0.024*\"platform\" + 0.020*\"problem\" + 0.020*\"code\" + 0.020*\"deposit\"\n",
      "Score: 0.18693907558918\t Topic: 0.031*\"money\" + 0.021*\"website\" + 0.021*\"portfolio\" + 0.021*\"way\" + 0.019*\"hour\"\n",
      "Score: 0.16559089720249176\t Topic: 0.054*\"app\" + 0.041*\"crypto\" + 0.035*\"kraken\" + 0.032*\"day\" + 0.031*\"time\"\n",
      "Score: 0.14564518630504608\t Topic: 0.071*\"account\" + 0.038*\"promise\" + 0.035*\"company\" + 0.033*\"star\" + 0.026*\"update\"\n",
      "Score: 0.14540106058120728\t Topic: 0.049*\"shib\" + 0.028*\"option\" + 0.025*\"error\" + 0.024*\"good\" + 0.022*\"people\"\n",
      "Score: 0.13292092084884644\t Topic: 0.048*\"fee\" + 0.033*\"coin\" + 0.030*\"transaction\" + 0.028*\"verification\" + 0.023*\"shiba\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = \"The fee is too high\"\n",
    "bow_vector = id2word.doc2bow(pre_process_unseen(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    # lda_mode[bow_vector] % gets the topic probability for a document\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))\n",
    "# TODO: Think about how to classify using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/UW2022/lda_crypto.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/UW2022/lda_crypto.ipynb#ch0000013vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# Save the model into memory\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/UW2022/lda_crypto.ipynb#ch0000013vscode-remote?line=1'>2</a>\u001b[0m lda_model\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m{\u001b[39;00mcsv_file[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m.model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the model into memory\n",
    "lda_model.save(f\"models/{csv_file[:-4]}.model\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
